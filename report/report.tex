\documentclass{llncs}
\usepackage{amsmath}  % this package needed for flalign

\begin{document}
\title{CS3243 PROJECT 1 REPORT}
\author{Jeremy Loye \and She Jiayu \and Sebastian Lie \and Tan Yuanhong}
\institute{National University of Singapore}
\maketitle

\section{Problem Specification}
We model the $k$-puzzle Problem as follows:
\begin{itemize}
	\item[] \textbf{State}
		A $n \times n$ array, with cells numbered by unique integers from $0$ to $k = n ^ 2 - 1$ inclusive, where $0$ represents an empty cell. Initial state is the array specified by input. Goal state is the array with integers $1$ to $n ^ 2 - 1$ occupying the first $n^2 - 1$ cells in order and $0$ occupying the last cell.
	\item[] \textbf{Actions}
		\texttt{LEFT}: Swap $0$ with number to its right.  \texttt{RIGHT}: Swap $0$ with number to its left. \texttt{UP}: Swap $0$ with number below it. \texttt{DOWN}: Swap $0$ with number above it.
	\item[] \textbf{Transition Model}
		\texttt{move(current\_state, action)} where \texttt{action} is one of \texttt{LEFT}, \texttt{RIGHT}, \texttt{UP}, \texttt{DOWN} and \texttt{current\_state} is the array representing the current arrangement of numbers in the grid.
	\item[] \textbf{Goal test}
		Test if the current state is equal to the goal state for every single cell.
	\item[] \textbf{Cost Function}
		Cost equals to the number of moves required for the initial state to transit into the current state.
\end{itemize}

\section{Technical Analysis}
All of our search algorithms are graph based, i.e. we maintain an \texttt{explored} set to keep track of the states that have been goal-tested and we do not add nodes whose states are in the \texttt{explored} set. We adopt the following convention for notations:
\begin{itemize}
    \item[] $n'$: successor of node $n$.
	\item[] $g(n)$: cost from root to $n$.
	\item[] $h(n)$: estimated cost from $n$ to goal node.
	\item[] $f(n)$: estimated cost from root to goal node passing through $n$.
	\item[] $c(n,n')$: step cost from node $n$ to $n'$.
\end{itemize}

\subsection{Uninformed Search - Breadth-First Search (BFS)}
\subsubsection{Correctness}
\begin{itemize}
	\item[] \textbf{Completeness}:
	Since BFS explores nodes in non-decreasing order of depth, as long as the branching factor $b$ is finite, BFS is able to find the goal node. In the context of $k$-puzzle, $b=4$ which is finite, so BFS is complete.
	\item[] \textbf{Optimality}
	Since BFS explores nodes in non-decreasing order of depth, it outputs the shallowest goal node. In the context of $k$-puzzle, since step cost is one, the depth of the node is equal to its cost. Hence, BFS outputs the goal node with the least cost, which is optimal.
\end{itemize}
\subsubsection{Complexity}
\begin{itemize}
	\item[] \textbf{Time complexity} of BFS is equal to the number of nodes visited before yielding the result, which can be calculated “layer-by-layer” by $1+b+b^2+\cdots +b^d = O(b^d)$, where $d$ is the depth of the goal node.
	\item[] \textbf{Space complexity} of BFS is equal to the maximum size of the frontier plus the maximum size of the explored set. Since BFS saves every generated node, the maximum size is $O(b^d)$ for both the explored set and the frontier, leading to a total complexity is $O(b^d)$.
\end{itemize}

\subsection{Informed Search - A* Search}
We assume that the heuristic used in A* is consistent, i.e. $h(n')+c(n,n') \geq h(n)$ for every pair of node $n$ and its corresponding successor $n'$.
\subsubsection{Correctness}
\begin{itemize}
	\item[] \textbf{Completeness}
	\begin{lemma} 
	Any finite graph search algorithm using a frontier queue is complete~\cite{sertac}.
	\end{lemma} 
	\begin{proof} 
	By induction on $n$, the number of steps from root $s$ to goal node $g$. \emph{Base case}: When $n=1$, $s$ is one step away from $g$, at the first step of such an algorithm will $g$ be added to the queue, so it is complete. \emph{Inductive step}: Suppose the lemma is true for $n=k$, consider the case for $n=k+1$. Since the $g$ is reachable from $s$, when adding the neighbors of $s$ to the queue, there exists at least one neighbor that can reach $g$ and is $k$ steps away from $g$. By the inductive hypothesis, the algorithm is complete. 
	\end{proof}
	\item[] \textbf{Optimality}
	\begin{lemma} 
	If $h$ is consistent, $f(n)$ is non-decreasing along any path.
	\end{lemma}
	\begin{proof}
	$f(n')=g(n')+h(n')=g(n)+c(n,n')+h(n') \geq g(n)+h(n)=f(n)$ 
	\end{proof}
	\begin{lemma} [Graph-separation property] In graph search, the frontier always separates the explored region of the search graph from the unexplored region. In other words, every path from the root to an unexplored node must include a node on the frontier~\cite{aima}. 
	\end{lemma}
	\begin{theorem}
	When A* (graph-based with consistent heuristic) selects a node $n$ for expansion, the shortest path to $n$ has been found. 
	\end{theorem}
	\begin{proof}
	Suppose otherwise. By graph-separation property, any path from the root $s$ to $n$ (since $n$ is not explored yet, otherwise A* will not select it for expansion) must include a node in the frontier. Since the shortest path to $n$ is not found yet, there must exist some node $t$ in the frontier such that it lies on the optimal path from $s$ to $n$. Since $t$ is on the path from $s$ to $n$ and is not $n$, by Lemma 2, $f(t)<f(n)$. As both $n$ and $t$ are in the frontier, A* will select $t$ to expand instead of $n$, which is a contradiction.
	\end{proof}
	By \textbf{Theorem 1}, we have that when goal node $g$ is reached, the shortest path from root $s$ to $g$ is found. This proves the optimality of A*.
\end{itemize}

\subsubsection{Complexity}
\begin{itemize}
	\item[] \textbf{Time complexity}: $O(b^{f^*(g)-f(g)})$, where $b$ is the branching factor and $f^*(g)$ is the actual cost from root $s$ to goal node $g$.
	\item[] \textbf{Space complexity}: $O(b^d)$, where $d$ is depth of the goal node.
\end{itemize}

\subsection{Heuristic 1 \& 2 - Misplaced Tiles \& Manhattan Distance}

Proof of consistency is given in AIMA, page 105~\cite{aima}.

\subsection{Heuristic 3 - Linear Conflict}

\begin{itemize}
\item[] The definition of linear conflict, the algorithm, and the idea for the proof is taken from \cite{lc}.
\item[]The full algorithm for calculating the linear conflict heuristic is given in the appendix.

\begin{definition}
Two tiles $t_j$ and $t_k$ are in a linear conflict if $t_j$ and $t_k$ are in the same line, the goal positions of $t_j$ and $t_k$ are both in that line, $t_j$ is to the right of $t_k$, and the goal position of $t_j$ is to the left of the goal position of $t_k$.
\end{definition}

The estimated cost of node $n$ by Linear Conflict heuristic is $h(n) = LC(n) + MD(n)$, where $MD(n)=\sum md(n,t_j)$ is the estimated cost given by Manhattan Distance heuristic, $LC(n) = 2\sum[lc(n,r_i) +lc(n,c_j)]$ where $lc(n,r_i)$ is the number of tiles to be removed from row i to attain 0 linear conflicts.
\begin{proof}
Consider the successor of a state obtained by moving a tile $t$ left or right along row $r_i$ of the $k$-puzzle. Since along $r_i$ tile $t$ is merely swapping places with an blank, number of linear conflicts of that row remains the same.
Denote $c_i$ as the initial column and $c_j$ as the goal column. Now we consider 3 mutually exclusive cases for horizontal moves.
\item[]\textbf{Case 1: The goal position of tile $t$ is neither on column $c_i$ nor $c_j$} \\
Since neither column is the goal column, we have $LC(n') = LC(n)$ and $MD(n') = MD(n) \pm 1$, so $f(n') = 1 + g(n) + LC(n) + MD(n') \geq g(n) + LC(n) + MD(n) = f(n)$.
\item[]\textbf{Case 2: The goal position of tile $t$ is column $c_i$} \\
Since tile $t$ moves out of its goal column, $LC(n') = LC(n)$ or $LC(n') = LC(n) - 2$ since $lc(n,c_i) - 1$, and $MD(n') = MD(n) + 1$. Thus we have $f(n') = 1 + g(n) + LC(n') + MD(n) + 1 \geq g(n) + LC(n) + MD(n) = f(n)$.
\item[]\textbf{Case 3: The goal position of tile $t$ is column $c_j$} \\
Since tile $t$ moves into its goal column, $LC(n') = LC(n)$ or $LC(n') = LC(n) + 2$, since $lc(n,c_j) + 1$, but $MD(n') = MD(n) - 1$. Thus we have $f(n') = 1 + g(n) + LC(n') + MD(n) - 1 \geq g(n) + LC(n) + MD(n) = f(n)$.  \\

\item[]A similar argument can be made for vertical moves. Hence, $f(n') \geq f(n)$ for any possible successor $n'$ of any state n. Thus the linear conflict heuristic is consistent.
\end{proof}
\end{itemize}

\section{Experimental Setup}
To examine the empirical time and space complexity of the 4 different algorithms implemented in this project, we wrote a generator to generate 10 random \textbf{solvable}~\cite{solvable} test cases for each dimension $3 \times 3$, $4 \times 4$ and $5 \times 5$, and then run the 4 algorithms on these test cases. For practicality of the experiment, we set a time limit of $60$ seconds for each test case. To avoid too many time limit exceeded (TLE) cases, we set a limit to the generator such that it only generates test cases whose solution depth is at most $100$.

We measure the solution depth, search depth, number of explored states, number of generated states, maximum heap size and runtime for each test case.

The number of explored/generated states and maximum heap size are used to assess the empirical space complexity while runtime is used to assess the empirical time complexity.

\section{Results and Discussion}
\begin{table}
	\centering
	\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c|c|c} \hline
		Dimension & \multicolumn{4}{c|}{$3 \times 3$} & \multicolumn{4}{c|}{$4 \times 4$} & \multicolumn{4}{c}{$5 \times 5$} \\\hline
		Solution & $1$ & $2$ & $3$ & $4$ & $1$ & $2$ & $3$ & $4$ & $1$ & $2$ & $3$ & $4$ \\\hline
		Pass Rate(\%) & 100 & 100 & 100 & 100 & 0 & 70 & 100 & 100 & 0 & 40 & 90 & 90 \\\hline
		Ave Solution Depth & 14.6 & 14.6 & 14.6 & 14.6 & - & 25.4 & 28.2 & 28.2 & - & 28.5 & 33.8 & 33.8 \\\hline
		Ave Search Depth & 14.6 & 14.6 & 14.6 & 14.6 & - & 25.4 & 28.2 & 28.2 & - & 28.5 & 33.8 & 33.8 \\\hline
		Ave Explored States & 10461.9 & 594.5 & 119.6 & 68.5 & - & 93122.4 & 25607.9 & 3486.7 & - & 95769 & 63719 & 9652.6 \\\hline
		Ave Generated States & 10461.9 & 948.6 & 197.2 & 116 & - & 177991.7 & 48460.2 & 6692.5 & - & 208102.5 & 136932.4 & 21830 \\\hline
		Ave Heap size & 3516.4 & 356.2 & 79.2 & 48.8 & - & 85254.9 & 23307.5 & 3270.5 & - & 112753 & 74193.9 & 12291.1 \\\hline
		Ave Runtime(s) & 0.201 & 0.0931 & 0.0773 & 0.0881 & - & 4.78 & 2.14 & 1.03 & - & 5.68 & 7.52 & 5.28 \\\hline
		Runtime SD(s) & 0.0157 & 0.0253 & 0.00856 & 0.0154 & - & 6.29 & 4.65 & 1.35 & - & 7.46 & 18.0 & 11.6 \\\hline
		Max Runtime(s) & 0.631 & 0.153 & 0.0916 & 0.119 & - & 19.1 & 15.8 & 4.58 & - & 18.4 & 58.1 & 38.0 \\\hline
	\end{tabular}
	\caption{Experimental results}
	\label{tab:one}
\end{table}
From the results, we can see that while all 4 algorithms manage to solve all 10 $3 \times 3$ puzzles, BFS got TLE for all $4 \times 4$ and $5 \times 5$ test cases. Among the 3 informed search heuristics, Manhattan Distance (MD) and Linear Conflict (LC) performed better than Misplaced Tile in terms of pass rate and both time and space complexity. Between MD and LC, LC outperformed MD in terms of both time and space complexity. This is consistent with the fact that LC dominates MD. There is an exception for the runtime for $3 \times 3$, this is most likely due to the overhead incurred in computing the estimated cost using LC, as it has a complexity of $O(n^3)$, where $n$ is the dimension of the grid.

\newpage

\bibliographystyle{splncs04}
\bibliography{report_bib}

\newpage
\section{Appendix}

\subsection{Linear Conflict Algorithm:}

we formalise the algorithm for calculating the linear conflict heuristic. \\
Definitions: \\
$c(t_j,r_i)$ is the number of conflicts in row $r_i$ that tile $t_j$ is in conflict with. \\
$lc(s, r_i)$ is the number of tiles that must be removed from row $r_i$ in order to resolve the linear conflicts of that row. $lc(s, c_i)$ is the number of tiles that must be removed from column $c_i$.  \\
$md(s, t_j)$ is the Manhattan Distance of tile $t_j$. \\
$LC(s)$ is the minimum number of additional moves necessary to resolve the linear conflicts in the current state s.\\
$MD(s)$ is the sum of the Manhattan Distances of all the tiles in s. \\

\textbf{Algorithm: Begin} \\
 
For each row $r_i$, \\
Set $lc(s, r_i) = 0$ \\
Obtain $c(t_j,r_i)$ for each $t_j$ in the row.

Then, while there is a non-zero $c(t_j,r_i)$ value, \\
    Find $max(c(t_k,r_i)) \ \forall t_k \in r_i$, call this tile $t_{max}$  \\
    Then set $c(t_{max},r_i) = 0$ \\
    And for any tile $t_k$ in conflict with $t_{max}$, $c(t_k,r_i) = c(t_k,r_i) - 1$ \\
    and $lc(s, r_i)++$

Do the same for each column $c_j$ \\
Then calculate $LC(s) = 2(\sum^K_{i=1} lc(s,r_i) + \sum^K_{j=1} lc(s,c_j))$
and  $MD(s) = \sum^{K^2}_{j=1}md(s,t_j)$
Then  $h(s) = MD(s) + LC(s)$. \\

\textbf{Algorithm: End} \\

Intuitively, we examine the puzzle state, row by row and column by column, and add to Manhattan Distance the minimum number of additional moves
necessary to resolve the conflicts within each row and column.

\subsection{Full Proof of Consistency of Linear Conflict}
We partition the proof of consistency into 2 parts. Since there are at most 4 successors of each node $n$, we partition the proof into when the action is along the row (left/right successors) and along the column (up/down successors).

We assume that the Manhattan Distance is consistent.

Let us first consider the successors obtained by moving along the row $r_i$ of the $k$-Puzzle. We observe that since along row $r_i$, tile $t$ is merely swapping places with an empty tile, it will not cause any change to the number of linear conflicts of that row.

WLOG, we denote $c_i$ as the initial column of a tile $n$ to be moved, and $c_j$ as the column tile $n$ moves to. In particular, if the move is valid, $c_j = c_i - 1, c_i + 1$.

Now we consider 3 mutually exclusive cases for tile $n$ and prove consistency for each of them.

\textbf{Case 1: The goal position of tile $t$ is neither on column $c_i$ nor $c_j$}

Since neither column is the goal column, the number of linear conflicts does not change, so no extra tile needs to be moved, and thus $LC(n') = LC(n)$. Besides, $MD(n') = MD(n) \pm 1 \implies MD(n') + 1 \geq MD(n)$. Thus we have:
\begin{align}
    f(n') \nonumber
    	&= g(n') + h(n') \\\nonumber
        &= c(n,n') + g(n) + LC(n') + MD(n') \\\nonumber
        &= 1 + g(n) + LC(n) + MD(n') \\\nonumber
        &= g(n) + LC(n) + [MD(n') + 1] \\\nonumber
        &\geq g(n) + LC(n) + MD(n) \\\nonumber
        &= g(n) + h(n) \\\nonumber
\end{align}

\textbf{Case 2: The goal position of tile $t$ is column $c_i$}

We only need consider the linear conflicts along the column $c_i$. Since tile $t$ moves out of its goal column, the number of linear conflicts could decrease if tile $t$ was in conflict with another tile along $c_i$, or stay the same if tile $t$ had no conflicts. This could reduce the number of tiles to be removed from column i, thus $lc(n',c_i) =lc(n,c_i)$ or $lc(n,c_i)-1 = lc(n',c_i)$. Thus $LC(n') = LC(n)$ or $LC(n') = LC(n) - 2 \implies LC(n') + 2 \geq LC(n)$. Since it will take $1$ more move to move tile $n$ back to its goal, $MD(n') = MD(n) + 1$. Thus we have:
\begin{align}
    f(n') \nonumber
    	&= g(n') + h(n') \\\nonumber
        &= c(n,n') + g(n) + LC(n') + MD(n') \\\nonumber
        &= 1 + g(n) + LC(n') + MD(n) + 1 \\\nonumber
        &= g(n) + [LC(n') + 2] + MD(n) \\\nonumber
        &\geq g(n) + LC(n) + MD(n) \\\nonumber
        &= g(n) + h(n) \\\nonumber
\end{align}

\textbf{Case 3: The goal position of tile $t$ is column $c_j$}

We only need to consider the linear conflicts along the column $c_j$. Since tile $t$ moves into its goal column, the number of linear conflicts could increase if tile $t$ is now in conflict with some tile along $c_j$, or stay the same if tile $t$ does not create conflicts in its new position. This could increase the number of tiles to be removed from column i, thus $lc(n',c_j) =lc(n,c_j)$ or $lc(n,c_j)+1 = lc(n',c_j)$. Thus $LC(n') = LC(n)$ or $LC(n') = LC(n) + 2 \implies LC(n') \geq LC(n)$. Since it takes $1$ less move to move tile $n$ back to its goal, $MD(n') = MD(n) - 1$. Thus we have:
\begin{align}
    f(s') \nonumber &= g(n') + h(n') \\\nonumber
        &= c(n,n') + g(n) + LC(n') + MD(n') \\\nonumber
        &= 1 + g(n) + LC(n') + MD(n) - 1 \\\nonumber
        &= g(n) + LC(n') + MD(n) \\\nonumber
        &\geq g(n) + LC(n) + MD(n) \\\nonumber
        &= g(n) + h(n) \\\nonumber
\end{align}

Therefore for all cases along the row of the puzzle, $f(n') \geq f(n)$. 

A similar argument can be made for the actions along the column of the $k$-Puzzle, by rotating the grid and interchanging the roles of rows and columns .

Thus $f(n') \geq f(n)$ for all possible successors of any state. This proves the consistency of Linear Conflict heuristic.

\subsection{Solvability of $k$-Puzzle}
The idea for the solvability of the $k$-Puzzle is taken from \cite{solvable}.
\begin{definition}
Flatten the $n \times n$ grid to a sequence of numbers, a pair of numbers $(a,b)$ is called an inversion if $a>b$ but $a$ comes before $b$ in the sequence. Inversion number of $k$-puzzle is the total number of inversions in the grid.
\end{definition}

Let $b$ be the number of the tile that moves.

\begin{lemma}
For any grid, a horizontal move does not change its inversion number.
\end{lemma}

\begin{proof}
Since the order of tile $b$ relative to other tiles in the grid remains the same after the move, the inversion number will not change.

Below is an example of a horizontal move in $8$-puzzle.
\begin{table}
	\centering
	\label{tab1}
	\begin{tabular}{|p{2mm}|p{2mm}|p{2mm}|} \hline
	x & x & x\\ \hline
	a & b & 0\\ \hline
	x & x & x\\ \hline
	\end{tabular}
\end{table}
\begin{table}
	\centering
	\label{tab2}
	\begin{tabular}{|p{2mm}|p{2mm}|p{2mm}|} \hline
	x & x & x\\ \hline
	a & 0 & b\\ \hline
	x & x & x\\ \hline
	\end{tabular}
\end{table}
\end{proof}

\newpage

\begin{lemma}
For any grid with odd size $n \times n$, the parity of the inversion number is invariant.
\end{lemma}

\begin{proof}
When tile $b$ moves horizontally, by \textbf{Lemma 4}, the inversion number does not change.

When tile $b$ moves vertically, it either moves in front of, or behind $n - 1$ tiles. Of these $n - 1$ tiles, suppose there are $p$ numbers that are greater than $b$, where $0 \leq p \leq n - 1$, then $n - 1 - p$ of them are smaller than $b$. The change in inversion number after $b$ has moved vertically is $p-(n-1-p) = 1-n$ if $b$ moves down, or $-p + (n-1-p) = n-1$ if $b$ moves up. Since $|n-1|$ is even, the move does not affect the parity of the inversion number.

Hence the parity of the inversion number never changes.

Below is an example of a vertical move in $8$-puzzle.
\begin{table}
	\centering
	\label{tab3}
	\begin{tabular}{|p{2mm}|p{2mm}|p{2mm}|} \hline
	a & x & x\\ \hline
	0 & c & d\\ \hline
	b & x & x\\ \hline
	\end{tabular}
\end{table}
\begin{table}
	\centering
	\label{tab4}
	\begin{tabular}{|p{2mm}|p{2mm}|p{2mm}|} \hline
	a & x & x\\ \hline
	b & c & d\\ \hline
	0 & x & x\\ \hline
\end{tabular}
\end{table}
\end{proof}

\begin{lemma}
For any grid with odd size $n \times n$, if its initial state has an odd number of inversions, it is unsolvable.
\end{lemma}

\begin{proof}
First, we note that the goal state has an inversion number of $0$. Since any legal move does not change the parity of inversion number, any legal move on a grid with an odd inversion number will result in an odd inversion number. Therefore legal moves on a grid with an odd inversion number will never result in $0$ inversions, and thus the puzzle is unsolvable.
\end{proof}

\begin{lemma}
For any grid with even size $n \times n$, moving a tile vertically always results in the change in parity of the inversion number.
\end{lemma}

\begin{proof}
When $b$ moves vertically, it either moves in front of, or behind $n-1$ tiles. Of these $n-1$ tiles, suppose there are $p$ numbers that are greater than $b$, where $0 \leq p \leq n-1$, then $n-1-p$ of them are smaller than $b$. The change in inversion number after $b$ has moved vertically is $p-(n-1-p) = 1-n$ if $b$ moves down, or $-p + (n-1-p) = n-1$ if $b$ moves up. Since $|n-1|$ is odd, the move always changes the parity of the number of inversions.
\end{proof}

\begin{lemma}
For any grid with even size $n \times n$, if the puzzle's initial state has an odd inversion number and its empty cell is on an odd-numbered row counting from the bottom, or has an even inversion number and its empty cell is on an even-numbered row counting from the bottom, it is unsolvable.
\end{lemma}

\begin{proof}
First we note that the goal state has an inversion number of $0$, with the empty cell on the first row from the bottom. Thus the goal state has an even inversion number with the empty cell on an odd-numbered row counting from the bottom.

We also note that having an odd inversion number and the empty cell on an odd-numbered row counting from the bottom is equivalent to an even inversion number and the empty cell on an even-numbered row counting from the bottom.

By \textbf{Lemma 4}, we know that horizontal moves do not change the inversion number.

If the initial state has an odd inversion number and the empty cell is on an odd-numbered row, then any vertical move made will result in an even inversion number with the empty cell on an even-numbered row, and vice versa. Therefore, if an initial state starts with an odd inversion number and the empty cell is on an odd-numbered row, it can never have an even inversion numbers with the empty cell on an odd-numbered row, and thus never reach the goal state. Therefore such puzzles are unsolvable.
\end{proof}


\end{document}